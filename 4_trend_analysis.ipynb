{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trend Analysis\n",
    "\n",
    "In this workshop, we're going to explore a 'data cube' - a medium-sized\\* vegetation dataset with x, y, and time dimensions.\n",
    "\n",
    "- What is a data cube anyway?  Is there higher-dimensional data?\n",
    "- Reducing data to a 1D timeseries\n",
    "- Calculating summaries along various dimensions\n",
    "- Dealing with unevenly-spaced observations and missing data\n",
    "- Drawing awesome plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First things first - as usual, we import the tools\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import pandas as pd  # \"Python ANd Data AnalysiS\" - like Excel, but better\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the course theory you will have heard how passive microwave observations from a series of satellite radiometers can be used to develop time series of a measure called Vegetation Optical Depth, and from this, global annual maps of above-ground biomass. We did this as part of a journal article that you can find in the reading material (Liu et al., 2015). Here we are going to look at these time series and do some trend analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I put the data on NCI for us, so you don't have to download it again.\n",
    "data = xr.open_dataset('http://dapds00.nci.org.au/thredds/dodsC/ub8/au/RegionTimeSeries/VOD_NCC2015_VOD_1993-2012.nc')\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By now, you should be familiar with the display above.  Perhaps you recognise the creator_name in the attributes metadata?\n",
    "\n",
    "An excellent piece of free software to visualise, explore and map NetCDF is *Panoply*, developed by NASA. [You can download it here](http://www.giss.nasa.gov/tools/panoply/). To avoid any problems with downloading and installing, we will not be using it in the tutorial, but if you will be using the netCDF data type it is strongly recommended for visual exploration and even for publishing nice-looking maps - it's *much* easier than MatLab, and still faster than Python (grumble grumble).\n",
    "\n",
    "*We're skipping a lot of stuff here, where xarray automatically handles things that are tedious and error-prone in Matlab.  Nice choice to use Python instead!*\n",
    "\n",
    "Because the dataset has only one attribute we're interested in, let's work with the data array instead of the data set (conceptually, a set of data arrays that happens to only have one entry).  Because this data is relatively small at 14MB, we'll also download the lot to save time later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VOD = data.VOD\n",
    "VOD.load()\n",
    "VOD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember that this array still has plenty of metadata - for example, you can see the time of each of the time steps by inspecting `VOD.time` in a new cell ('Insert > Insert Cell Below' in the menu)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just to show off, let's make a grid with a VOD map for every timestep\n",
    "VOD.plot.imshow(robust=True, col='time', col_wrap=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why is the world map on its side?  That's just how the data is stored in this file!  You can change the order of dimensions using [`VOD.transpose('time', 'lat', 'lon')`](http://xarray.pydata.org/en/stable/reshaping.html#reordering-dimensions) (for example), but in this notebook we're going to be reducing the dimensionality of the data and analysing it in a more traditional format (tables! timeseries! statistics!) so it doesn't matter much.  This is of course only possible because we can use the metadata to operate on dimensions by name - much better than having to remember if latitude is `1` or `2` in every file!\n",
    "\n",
    "## Above-ground Biomass Carbon\n",
    "\n",
    "In our (ed. note: Albert's) study we used existing biomass data to develop an equation that predicts Above-ground Biomass Carbon (ABC, in MgC/ha - or 10^6 grammes Carbon per hectare) from Vegetation Optical Depth (VOD). This is called a _retrieval algorithm_, albeit in this case only a partial one: VOD itself was derived from the original passive microwave brightness temperatures using a retrieval algorithm, and in a second step we are extending this to find ABC. The ABC retrieval algorithm can be applied directly to the whole data cube.\n",
    "\n",
    "You can find the origin and description of the equation in our article). The _arctan_ command calculates the inverse tangent (trigonometric function, with the result in radians).  Numpy supplies so many such situationally useful functions that nobody remembers them all - just look it up as I looked up arctan when writing this!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Coefficients\n",
    "a = 320.6\n",
    "b = 9.10\n",
    "c = 0.95\n",
    "d = 5.5\n",
    "# The equation\n",
    "ABC = a * ( np.arctan( b*(VOD-c) ) - np.arctan( b*(0-c) ) ) / (np.arctan( b*(np.inf-c) ) - np.arctan( b*(0-c) ) ) + d\n",
    "ABC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well, the equation worked - but there are two problems.  We've lost our attributes metadata, and the array is still called VOD!  Let's fix both of those:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ABC.name = 'ABC'\n",
    "ABC.attrs = {\n",
    "    'long_name': 'Above-ground Biomass Carbon',\n",
    "    'units': 'MgC/ha (mega-grams of Carbon per hectare)',\n",
    "    'comment': 'Derived from vegetation optical depth.  See Liu et al., 2015.',\n",
    "    'author': 'Your name goes here!',\n",
    "}\n",
    "# Ah, much better - plots will be correctly labelled, and your name will appear if you save the file.\n",
    "ABC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the next-to-last time step, transpose the axes, and plot:\n",
    "ABC.isel(time=-1).T.plot.imshow(robust=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may notice that ABC is much more concentrated (mainly in the tropics and boreal forests) than VOD was. This is because of the non-linear shape of the retrieval algorithm.\n",
    "\n",
    "## Reducing data to one dimension\n",
    "\n",
    "Let's reduce our data to the mean along a latitude dimension so we can inspect this relationship more closely."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abc_1d = ABC.mean(dim=['time', 'lon'])\n",
    "abc_1d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While we can work with low-dimensioned and smaller data in xarray, it's not at it's strongest - because xarray must support all its capabilities for very large and high-dimensioned data too.  We'll have a quick look at this approach, then demonstrate pandas.\n",
    "\n",
    "[Pandas, short for 'Python ANd Data AnalysiS'](http://pandas.pydata.org/pandas-docs/stable/), is a powerful and concise package for working with one and two-dimensional data.  It has excellent statistical tools built-in, and makes it easy to manipulate and summarise data.  If you could do it in Excel, Pandas is probably the best way to do it in Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xarray can still plot 1D arrays, of course.  \n",
    "# Try abc_1d.<tab> to see what other plots are available!\n",
    "abc_1d.plot.line()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert our lat_abc array to a dataframe (called df by convention)\n",
    "# then look at a summary.  This is more impressive with multiple columns!\n",
    "df = abc_1d.to_dataframe()\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interpretation: `mean` has only counted values that are not `nan`, and therefore terrestrial areas only.  There are clear peaks around 60 (Siberia), 5 to -10 degrees (the Amazon, central Africa, Indonesia, etc. - the tropics).\n",
    "\n",
    "A few differences between Xarray and Pandas are apparent even for this super-simple plot.\n",
    "\n",
    "- Pandas has used a legend, where Xarray used a y-axis label.  This is because Pandas can draw the same plot with multiple columns (lines), which may not have identical units.\n",
    "- Our latitude coordinates actually count down from 90 degrees.  Xarray puts the coordinates in ascending order for display, while Pandas displays exactly what you give it.\n",
    "- Xarray has limited the plot axis to the part that has data (as our mean ABC in the southern ocean is `nan`, i.e. missing data).  Pandas is often used for things where it's important to distinguish between 'out of range' and 'in range but missing' data, so it does not adjust the axis.\n",
    "\n",
    "You may prefer one approach or the other, and that's OK - it's simply good to be aware that they treat labelled data a little differently.  In short, Xarray labels must be coordinates ordered in some dimension - but Pandas can label data with almost anything.\n",
    "\n",
    "## Selecting data by coordinates\n",
    "\n",
    "If you have been working through the [Software Carpentry](https://software-carpentry.org/lessons/) or [*Think Python*](http://greenteapress.com/wp/think-python-2e/) materials, as I suggest you do, you will be familiar with integer-based indexing.  (recap: `some_list[n]` is the item `n` places after the start of the list).  \n",
    "\n",
    "This also works on xarray data, using `data.isel(time=0)` - index selection of the first step along the time dimension.  However, we will usually be interested in selecting data based on the coordinates - either a single point, or a smaller area.  [The xarray documentation](http://xarray.pydata.org/en/stable/indexing.html) describes this in detail - let's just look at the two most common examples.\n",
    "\n",
    "First, selecting a single point - we'll use Canberra as our example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This doesn't work, because the exact coordinates we gave aren't in the index\n",
    "ABC.sel(lat=-35.5, lon=148.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instead, we should explicitly ask for the nearest point to the location we want.\n",
    "# You might also give an optional tolerance=0.2 argument, with n the maximum acceptable distance \n",
    "# (in this example, 0.2 degrees).  What happens with tolerance=0.1 ?\n",
    "point = ABC.sel(lat=-35.5, lon=148.75, method='nearest', )\n",
    "point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can see the 2003 bushfires, and also the 2009/10 la nina\n",
    "point.plot()\n",
    "plt.title('Mean ABC, Canberra')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Selecting an area is a bit different, because you can't ask for the nearest area.  Instead, you ask for all pixels within a given boundary as represented with `slice(start_coord, end_coord)` objects.  Be careful with the order of your coordinates - if the coordinates are decreasing, the end_coord must be smaller than the start_coord!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define our boundaries\n",
    "aus_lats = slice(-10, -45)\n",
    "aus_lons = slice(112, 155)\n",
    "# Select the australian data, and name the datacube \"aus\"\n",
    "aus = ABC.sel(lat=aus_lats, lon=aus_lons)\n",
    "# Plot, after taking the mean along the time dimension and transposing\n",
    "aus.mean(dim='time').T.plot.imshow(robust=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can also reduce this area to a 1D timeseries, and plot that:\n",
    "aus.mean(dim=['lat', 'lon']).plot()\n",
    "plt.title('Mean ABC, Australia')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time-series analysis\n",
    "\n",
    "TODO:\n",
    "\n",
    "- Saving pandas dataframes to CSV for Excel etc\n",
    "- Saving Xarray data to netcdf for Arc or Qgis etc.\n",
    "- Using scipy.stats for linear regression (noting that mean, median, stdev, etc are built in to arrays)\n",
    "- Per-pixel regression of an area (vectorised if possible, looping if not)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This workshop notebook is incomplete.\n",
    "\n",
    "Please ask Zac for suggestions if you're working this far ahead!"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:remote-sensing]",
   "language": "python",
   "name": "conda-env-remote-sensing-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
